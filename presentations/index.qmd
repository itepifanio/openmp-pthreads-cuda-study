---
title: "AnÃ¡lise Artigo 01"
subtitle: "Performance Analysis of Parallel Programming Paradigms on CPU-GPU Clusters"
format:
  revealjs:
    slide-number: true
    transition: fade
---

# Pergunta motivadora

Qual modelo de programaÃ§Ã£o paralela (OpenMP ou CUDA) Ã© mais eficiente nos algoritmos BFS e DFS em grafos grandes?

## BFS (Busca em largura) & DFS (Busca em profundidade)

### Descrever cada algoritmo mostrando o uso de GMask e pragma

## **Performance Comparison: OpenMP vs. CUDA**
| BFS/DFS | OpenMP (CPU) | CUDA (GPU) |
|---------|-------------|------------|
| Execution Model | Multi-threaded | Massively Parallel |
| Performance | Slower due to thread overhead | 187x-240x speedup |
| Graph Size Handling | Limited | Handles massive graphs efficiently |

## **Key Observations**
ğŸ”¹ **CPU (OpenMP) suffers from:** Thread idling, synchronization costs, and inefficient memory access.
ğŸ”¹ **GPU (CUDA) benefits from:** Thousands of cores executing in parallel, optimized memory use.
ğŸ”¹ **CUDA is significantly faster (187x-240x)** for BFS & DFS on large graphs.

## **Future Work & Open Questions**
âœ… Can we use **hybrid CPU-GPU models** for better performance?
âœ… How can **memory optimizations** improve CUDA BFS?
âœ… What if we test **real-world applications** (social networks, AI pathfinding)?

## **Final Takeaways**
ğŸš€ CUDA **significantly outperforms** OpenMP for BFS/DFS.
ğŸ› ï¸ Understanding **parallel execution models** is critical for HPC & AI.
ğŸ” **Future research can focus on optimizations & hybrid models.**

## **Q&A** ğŸ’¡
Let's discuss where we can apply these concepts!

